{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10827165,"sourceType":"datasetVersion","datasetId":6723075}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nRDD2022 BASELINE TRAINING - YOLOv8n @ 640\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nModel: YOLOv8n (Nano - fastest, baseline)\nResolution: 640Ã—640\nEpochs: 100\nDataset: 38,385 images (RDD2022)\nTarget: 45-50% mAP50\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\"\"\"\n\nimport os\nimport sys\n\nprint(\"=\"*70)\nprint(\"RDD2022 - BASELINE TRAINING (YOLOv8n @ 640)\")\nprint(\"=\"*70)\n\n# âœ… CRITICAL: Fix NumPy FIRST before importing anything\nprint(\"\\nğŸ“¦ Step 1: Fixing NumPy compatibility...\")\nprint(\"   Uninstalling NumPy 2.x...\")\n!pip uninstall -y -q numpy\n\nprint(\"   Installing NumPy 1.26.4 + Ultralytics...\")\n!pip install -q \"numpy==1.26.4\" ultralytics\n\nprint(\"\\nâœ… Step 2: Verifying installation...\")\n\n# Now import everything\nfrom pathlib import Path\nimport shutil\nimport json\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport cv2\nimport torch\nimport pandas as pd\n\nprint(f\"\\nğŸ“Š Package Versions:\")\nprint(f\"   - NumPy:   {np.__version__} {'âœ…' if np.__version__.startswith('1') else 'âŒ'}\")\nprint(f\"   - OpenCV:  {cv2.__version__}\")\nprint(f\"   - PyTorch: {torch.__version__}\")\nprint(f\"   - CUDA:    {torch.cuda.is_available()}\")\n\n# âœ… Test NumPy/OpenCV compatibility\ntry:\n    test_img = np.zeros((10, 10, 3), dtype=np.uint8)\n    resized = cv2.resize(test_img, (20, 20))\n    print(f\"   - OpenCV/NumPy: âœ… PASSED\")\nexcept Exception as e:\n    print(f\"   - OpenCV/NumPy: âŒ FAILED ({e})\")\n    print(\"   âš ï¸  RESTART KERNEL and run this cell again!\")\n\n# âœ… Disable WandB\nos.environ['WANDB_DISABLED'] = 'true'\nos.environ['WANDB_MODE'] = 'disabled'\nos.environ['WANDB_SILENT'] = 'true'\n\nfrom ultralytics import YOLO, settings\nsettings.update({'wandb': False})\n\nif torch.cuda.is_available():\n    print(f\"\\nğŸ® GPU Information:\")\n    print(f\"   - Device: {torch.cuda.get_device_name(0)}\")\n    print(f\"   - Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… SETUP COMPLETE - Ready for Training!\")\nprint(\"=\"*70 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:56:28.218461Z","iopub.execute_input":"2025-12-09T19:56:28.219231Z","iopub.status.idle":"2025-12-09T19:56:36.283427Z","shell.execute_reply.started":"2025-12-09T19:56:28.219205Z","shell.execute_reply":"2025-12-09T19:56:36.282584Z"},"editable":false},"outputs":[{"name":"stdout","text":"======================================================================\nRDD2022 - BASELINE TRAINING (YOLOv8n @ 640)\n======================================================================\n\nğŸ“¦ Step 1: Fixing NumPy compatibility...\n   Uninstalling NumPy 2.x...\n   Installing NumPy 1.26.4 + Ultralytics...\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\nâœ… Step 2: Verifying installation...\n\nğŸ“Š Package Versions:\n   - NumPy:   1.26.4 âœ…\n   - OpenCV:  4.11.0\n   - PyTorch: 2.6.0+cu124\n   - CUDA:    True\n   - OpenCV/NumPy: âœ… PASSED\n\nğŸ® GPU Information:\n   - Device: Tesla P100-PCIE-16GB\n   - Memory: 15.89 GB\n\n======================================================================\nâœ… SETUP COMPLETE - Ready for Training!\n======================================================================\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\"\"\"\nDATASET CONFIGURATION\nVerify paths and create data.yaml\n\"\"\"\n\n# Dataset paths\nDATASET_BASE = Path(\"/kaggle/input/rdd-2022/RDD_SPLIT\")\n\n# Verify dataset exists\nprint(\"ğŸ“‚ Verifying Dataset...\\n\")\n\nif not DATASET_BASE.exists():\n    print(\"âŒ Dataset not found!\")\n    print(\"ğŸ’¡ Make sure to add 'rdd-2022' dataset to this notebook\")\n    print(\"\\nSearching for dataset...\")\n    for item in Path(\"/kaggle/input/\").iterdir():\n        print(f\"   Found: {item.name}\")\nelse:\n    print(f\"âœ… Dataset found: {DATASET_BASE}\\n\")\n\nsplits = ['train', 'val', 'test']\ndataset_info = {}\n\nfor split in splits:\n    img_dir = DATASET_BASE / split / \"images\"\n    lbl_dir = DATASET_BASE / split / \"labels\"\n    \n    n_images = len(list(img_dir.glob(\"*.jpg\"))) if img_dir.exists() else 0\n    n_labels = len(list(lbl_dir.glob(\"*.txt\"))) if lbl_dir.exists() else 0\n    \n    dataset_info[split] = {'images': n_images, 'labels': n_labels}\n    \n    status = \"âœ…\" if n_images > 0 and n_labels > 0 else \"âŒ\"\n    print(f\"{status} {split:8s}: {n_images:6,} images, {n_labels:6,} labels\")\n\n# Class names\nCLASS_NAMES = [\n    'longitudinal crack',\n    'transverse crack', \n    'alligator crack',\n    'other corruption',\n    'Pothole'\n]\n\nprint(f\"\\nğŸ·ï¸  Damage Classes ({len(CLASS_NAMES)}):\")\nfor i, name in enumerate(CLASS_NAMES):\n    print(f\"   {i}: {name}\")\n\n# Create data.yaml in working directory\ndata_yaml_content = f\"\"\"# RDD2022 Dataset Configuration\n# Baseline Training: YOLOv8n @ 640\n# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\npath: {DATASET_BASE}\ntrain: train/images\nval: val/images\ntest: test/images\n\nnc: 5\nnames:\n  0: longitudinal crack\n  1: transverse crack\n  2: alligator crack\n  3: other corruption\n  4: Pothole\n\"\"\"\n\ndata_yaml_path = Path(\"/kaggle/working/data.yaml\")\nwith open(data_yaml_path, 'w') as f:\n    f.write(data_yaml_content)\n\nprint(f\"\\nâœ… data.yaml created: {data_yaml_path}\")\nprint(\"\\n\" + \"=\"*70 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:56:36.285383Z","iopub.execute_input":"2025-12-09T19:56:36.285712Z","iopub.status.idle":"2025-12-09T19:56:36.796985Z","shell.execute_reply.started":"2025-12-09T19:56:36.285680Z","shell.execute_reply":"2025-12-09T19:56:36.796133Z"},"editable":false},"outputs":[{"name":"stdout","text":"ğŸ“‚ Verifying Dataset...\n\nâœ… Dataset found: /kaggle/input/rdd-2022/RDD_SPLIT\n\nâœ… train   : 26,869 images, 26,869 labels\nâœ… val     :  5,758 images,  5,758 labels\nâœ… test    :  5,758 images,  5,758 labels\n\nğŸ·ï¸  Damage Classes (5):\n   0: longitudinal crack\n   1: transverse crack\n   2: alligator crack\n   3: other corruption\n   4: Pothole\n\nâœ… data.yaml created: /kaggle/working/data.yaml\n\n======================================================================\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\"\"\"\nRESULTS SAVER - NEVER LOSE TRAINING RESULTS!\nAutomatically saves everything after training\n\"\"\"\n\nclass TrainingResultsSaver:\n    \"\"\"\n    Bulletproof results saver for Kaggle training\n    Saves weights, metrics, plots, and creates downloadable archive\n    \"\"\"\n    \n    def __init__(self, experiment_name):\n        self.exp_name = experiment_name\n        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \n        # Create save directory\n        self.save_dir = Path(f\"/kaggle/working/{experiment_name}_{self.timestamp}\")\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n        \n        self.metadata = {\n            'experiment': experiment_name,\n            'timestamp': self.timestamp,\n            'status': 'initialized'\n        }\n        \n        print(f\"ğŸ’¾ ResultsSaver initialized: {self.save_dir}\")\n    \n    def save_training_run(self, model, results_dir, config):\n        \"\"\"\n        Save complete training run\n        \n        Args:\n            model: Trained YOLO model\n            results_dir: Path to training results (e.g., 'runs/detect/train')\n            config: Training configuration dict\n        \"\"\"\n        print(f\"\\n{'='*70}\")\n        print(f\"ğŸ’¾ SAVING TRAINING RESULTS: {self.exp_name}\")\n        print(f\"{'='*70}\\n\")\n        \n        results_path = Path(results_dir)\n        \n        # 1. Save weights\n        weights_dir = results_path / \"weights\"\n        if weights_dir.exists():\n            save_weights_dir = self.save_dir / \"weights\"\n            save_weights_dir.mkdir(exist_ok=True)\n            \n            for weight_file in [\"best.pt\", \"last.pt\"]:\n                src = weights_dir / weight_file\n                if src.exists():\n                    shutil.copy(src, save_weights_dir / weight_file)\n                    file_size_mb = src.stat().st_size / (1024 * 1024)\n                    print(f\"âœ… Saved: weights/{weight_file} ({file_size_mb:.2f} MB)\")\n        \n        # 2. Save results.csv\n        results_csv = results_path / \"results.csv\"\n        if results_csv.exists():\n            shutil.copy(results_csv, self.save_dir / \"results.csv\")\n            print(f\"âœ… Saved: results.csv\")\n            \n            # Parse final metrics\n            df = pd.read_csv(results_csv)\n            final_metrics = df.iloc[-1].to_dict()\n            \n            # Handle different column naming conventions\n            map50_col = 'metrics/mAP50(B)' if 'metrics/mAP50(B)' in final_metrics else 'metrics/mAP_0.5'\n            map_col = 'metrics/mAP50-95(B)' if 'metrics/mAP50-95(B)' in final_metrics else 'metrics/mAP_0.5:0.95'\n            precision_col = 'metrics/precision(B)' if 'metrics/precision(B)' in final_metrics else 'metrics/precision'\n            recall_col = 'metrics/recall(B)' if 'metrics/recall(B)' in final_metrics else 'metrics/recall'\n            \n            self.metadata['final_metrics'] = {\n                'mAP50': float(final_metrics.get(map50_col, 0)),\n                'mAP50-95': float(final_metrics.get(map_col, 0)),\n                'precision': float(final_metrics.get(precision_col, 0)),\n                'recall': float(final_metrics.get(recall_col, 0)),\n            }\n            \n            print(f\"\\nğŸ“Š Final Metrics:\")\n            print(f\"   mAP@50:    {self.metadata['final_metrics']['mAP50']:.4f}\")\n            print(f\"   mAP@50-95: {self.metadata['final_metrics']['mAP50-95']:.4f}\")\n            print(f\"   Precision: {self.metadata['final_metrics']['precision']:.4f}\")\n            print(f\"   Recall:    {self.metadata['final_metrics']['recall']:.4f}\")\n        \n        # 3. Save plots\n        plots_dir = self.save_dir / \"plots\"\n        plots_dir.mkdir(exist_ok=True)\n        \n        plot_files = [\n            \"results.png\", \"confusion_matrix.png\", \"confusion_matrix_normalized.png\",\n            \"F1_curve.png\", \"P_curve.png\", \"R_curve.png\", \"PR_curve.png\",\n            \"labels.jpg\", \"labels_correlogram.jpg\", \"train_batch0.jpg\",\n            \"train_batch1.jpg\", \"train_batch2.jpg\", \"val_batch0_labels.jpg\",\n            \"val_batch0_pred.jpg\", \"val_batch1_labels.jpg\", \"val_batch1_pred.jpg\",\n            \"val_batch2_labels.jpg\", \"val_batch2_pred.jpg\"\n        ]\n        \n        saved_plots = 0\n        for plot in plot_files:\n            src = results_path / plot\n            if src.exists():\n                shutil.copy(src, plots_dir / plot)\n                saved_plots += 1\n        \n        print(f\"\\nâœ… Saved: plots/ ({saved_plots} files)\")\n        \n        # 4. Save configuration\n        config_path = self.save_dir / \"config.json\"\n        with open(config_path, 'w') as f:\n            # Convert Path objects to strings for JSON serialization\n            config_serializable = {k: str(v) if isinstance(v, Path) else v for k, v in config.items()}\n            json.dump(config_serializable, f, indent=4)\n        print(f\"âœ… Saved: config.json\")\n        \n        # 5. Save metadata\n        self.metadata['status'] = 'completed'\n        self.metadata['config'] = config_serializable\n        \n        metadata_path = self.save_dir / \"metadata.json\"\n        with open(metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=4)\n        print(f\"âœ… Saved: metadata.json\")\n        \n        # 6. Create results summary\n        self._create_summary()\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"âœ… ALL RESULTS SAVED TO: {self.save_dir}\")\n        print(f\"{'='*70}\\n\")\n        \n        return self.save_dir\n    \n    def _create_summary(self):\n        \"\"\"Create human-readable summary\"\"\"\n        summary = f\"\"\"\n{'='*70}\nTRAINING SUMMARY: {self.exp_name}\n{'='*70}\nTimestamp: {self.timestamp}\nStatus: {self.metadata['status']}\n\nFINAL METRICS:\n\"\"\"\n        if 'final_metrics' in self.metadata:\n            metrics = self.metadata['final_metrics']\n            summary += f\"  mAP@50:      {metrics['mAP50']:.4f} ({metrics['mAP50']*100:.2f}%)\\n\"\n            summary += f\"  mAP@50-95:   {metrics['mAP50-95']:.4f} ({metrics['mAP50-95']*100:.2f}%)\\n\"\n            summary += f\"  Precision:   {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\\n\"\n            summary += f\"  Recall:      {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\\n\"\n        \n        summary += f\"\\nCONFIGURATION:\\n\"\n        if 'config' in self.metadata:\n            key_params = ['model', 'epochs', 'imgsz', 'batch', 'patience', 'optimizer', 'amp']\n            for key in key_params:\n                if key in self.metadata['config']:\n                    summary += f\"  {key:15s}: {self.metadata['config'][key]}\\n\"\n        \n        summary += f\"\\n{'='*70}\\n\"\n        \n        summary_path = self.save_dir / \"SUMMARY.txt\"\n        with open(summary_path, 'w') as f:\n            f.write(summary)\n        \n        print(summary)\n        \n        return summary_path\n    \n    def create_archive(self):\n        \"\"\"Create ZIP archive for download\"\"\"\n        import zipfile\n        \n        zip_path = f\"{self.save_dir}.zip\"\n        \n        print(f\"\\nğŸ“¦ Creating downloadable archive...\")\n        \n        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for file in self.save_dir.rglob('*'):\n                if file.is_file():\n                    arcname = file.relative_to(self.save_dir.parent)\n                    zipf.write(file, arcname)\n        \n        size_mb = Path(zip_path).stat().st_size / (1024 * 1024)\n        print(f\"âœ… Archive created: {Path(zip_path).name}\")\n        print(f\"ğŸ“Š Size: {size_mb:.2f} MB\")\n        print(f\"\\n{'='*70}\")\n        print(f\"ğŸš¨ DOWNLOAD THIS FILE IMMEDIATELY!\")\n        print(f\"{'='*70}\")\n        print(f\"1. Look in /kaggle/working/ folder (left sidebar)\")\n        print(f\"2. Find: {Path(zip_path).name}\")\n        print(f\"3. Right-click â†’ Download\")\n        print(f\"4. Save to your local machine NOW!\")\n        print(f\"{'='*70}\\n\")\n        \n        return zip_path\n\n\nprint(\"âœ… TrainingResultsSaver class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:56:36.797812Z","iopub.execute_input":"2025-12-09T19:56:36.798031Z","iopub.status.idle":"2025-12-09T19:56:36.817846Z","shell.execute_reply.started":"2025-12-09T19:56:36.798011Z","shell.execute_reply":"2025-12-09T19:56:36.817085Z"},"editable":false},"outputs":[{"name":"stdout","text":"âœ… TrainingResultsSaver class defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\"\"\"\nTRAINING CONFIGURATION\nOptimized with AMP and Plots enabled\n\"\"\"\n\n# Experiment name\nEXPERIMENT_NAME = \"baseline_yolov8n_640\"\n\n# Training configuration - FULLY OPTIMIZED\nTRAINING_CONFIG = {\n    'model': 'yolov8n.pt',\n    'data': str(data_yaml_path),\n    'epochs': 100,\n    'imgsz': 640,\n    'batch': 16,\n    'device': 0,\n    'project': '/kaggle/working/runs',\n    'name': 'train',\n    'patience': 20,\n    'save': True,\n    'save_period': 10,\n    'cache': True,\n    'workers': 8,\n    'optimizer': 'auto',\n    'verbose': True,\n    'seed': 42,\n    'deterministic': True,\n    'single_cls': False,\n    'rect': False,\n    'cos_lr': False,\n    'close_mosaic': 10,\n    'resume': False,\n    'amp': True,        # âœ… ENABLED - Faster training (15% speedup)\n    'plots': True,      # âœ… ENABLED - Auto-generate training plots\n    'fraction': 1.0,\n    'profile': False,\n    'freeze': None,\n    'lr0': 0.01,\n    'lrf': 0.01,\n    'momentum': 0.937,\n    'weight_decay': 0.0005,\n    'warmup_epochs': 3.0,\n    'warmup_momentum': 0.8,\n    'warmup_bias_lr': 0.1,\n    'box': 7.5,\n    'cls': 0.5,\n    'dfl': 1.5,\n    'val': True,\n}\n\nprint(\"=\"*70)\nprint(\"TRAINING CONFIGURATION - OPTIMIZED\")\nprint(\"=\"*70)\nprint(f\"\\nğŸ”§ Model Configuration:\")\nprint(f\"   Model:       {TRAINING_CONFIG['model']}\")\nprint(f\"   Resolution:  {TRAINING_CONFIG['imgsz']}Ã—{TRAINING_CONFIG['imgsz']}\")\nprint(f\"   Epochs:      {TRAINING_CONFIG['epochs']}\")\nprint(f\"   Batch Size:  {TRAINING_CONFIG['batch']}\")\nprint(f\"   Device:      GPU {TRAINING_CONFIG['device']}\")\nprint(f\"   Patience:    {TRAINING_CONFIG['patience']} epochs\")\nprint(f\"   AMP:         {TRAINING_CONFIG['amp']} âœ… (Fast training)\")\nprint(f\"   Plots:       {TRAINING_CONFIG['plots']} âœ… (Auto-generated)\")\n\nprint(f\"\\nğŸ“Š Dataset:\")\nprint(f\"   Train:       {dataset_info['train']['images']:,} images\")\nprint(f\"   Val:         {dataset_info['val']['images']:,} images\")\nprint(f\"   Test:        {dataset_info['test']['images']:,} images\")\nprint(f\"   Classes:     {len(CLASS_NAMES)}\")\n\nprint(f\"\\nâš¡ Performance:\")\nprint(f\"   Estimated Time: ~6-8 hours (with AMP)\")\nprint(f\"   Speed Boost:    ~15% faster than without AMP\")\nprint(f\"   Plots:          15+ auto-generated visualizations\")\n\nprint(f\"\\nğŸ¯ Target: 45-50% mAP@50\")\nprint(\"\\n\" + \"=\"*70 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:56:36.819730Z","iopub.execute_input":"2025-12-09T19:56:36.819944Z","iopub.status.idle":"2025-12-09T19:56:36.839622Z","shell.execute_reply.started":"2025-12-09T19:56:36.819929Z","shell.execute_reply":"2025-12-09T19:56:36.838848Z"},"editable":false},"outputs":[{"name":"stdout","text":"======================================================================\nTRAINING CONFIGURATION - OPTIMIZED\n======================================================================\n\nğŸ”§ Model Configuration:\n   Model:       yolov8n.pt\n   Resolution:  640Ã—640\n   Epochs:      100\n   Batch Size:  16\n   Device:      GPU 0\n   Patience:    20 epochs\n   AMP:         True âœ… (Fast training)\n   Plots:       True âœ… (Auto-generated)\n\nğŸ“Š Dataset:\n   Train:       26,869 images\n   Val:         5,758 images\n   Test:        5,758 images\n   Classes:     5\n\nâš¡ Performance:\n   Estimated Time: ~6-8 hours (with AMP)\n   Speed Boost:    ~15% faster than without AMP\n   Plots:          15+ auto-generated visualizations\n\nğŸ¯ Target: 45-50% mAP@50\n\n======================================================================\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\"\"\"\nLOAD MODEL AND START TRAINING\nâš ï¸ This cell will run for approximately 6-8 hours\nâš ï¸ Do NOT close this notebook while training!\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"STARTING BASELINE TRAINING\")\nprint(\"=\"*70)\n\n# Initialize results saver\nsaver = TrainingResultsSaver(EXPERIMENT_NAME)\n\n# Load pretrained YOLOv8n model\nprint(\"\\nğŸ“¥ Loading YOLOv8n pretrained model...\")\nmodel = YOLO(TRAINING_CONFIG['model'])\n\nprint(f\"âœ… Model loaded: {TRAINING_CONFIG['model']}\")\n\n# Count model parameters\ntotal_params = sum(p.numel() for p in model.model.parameters())\ntrainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n\nprint(f\"ğŸ“Š Model Information:\")\nprint(f\"   Total Parameters:     {total_params:,}\")\nprint(f\"   Trainable Parameters: {trainable_params:,}\")\nprint(f\"   Model Size:           ~6.3 MB\")\n\n# Start training\nprint(f\"\\n{'='*70}\")\nprint(f\"ğŸš€ STARTING TRAINING\")\nprint(f\"{'='*70}\")\nprint(f\"\\nâ±ï¸  Estimated Duration: 6-8 hours\")\nprint(f\"ğŸ“Š Progress will be shown below\")\nprint(f\"âš ï¸  Do NOT close this notebook!\")\nprint(f\"\\n{'='*70}\\n\")\n\n# Record start time\nstart_time = datetime.now()\nprint(f\"â° Training started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n\n# Train the model\ntry:\n    results = model.train(**TRAINING_CONFIG)\n    \n    # Record end time\n    end_time = datetime.now()\n    duration = end_time - start_time\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"ğŸ‰ TRAINING COMPLETE!\")\n    print(f\"{'='*70}\")\n    print(f\"â° Started:  {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(f\"â° Finished: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(f\"â±ï¸  Duration: {duration}\")\n    print(f\"{'='*70}\\n\")\n    \n    # Get results directory\n    results_dir = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name']\n    print(f\"ğŸ“ Results directory: {results_dir}\")\n    \n    # Verify results exist\n    if results_dir.exists():\n        print(f\"âœ… Training results saved successfully\")\n    else:\n        print(f\"âš ï¸  Warning: Results directory not found\")\n        \nexcept Exception as e:\n    print(f\"\\n{'='*70}\")\n    print(f\"âŒ ERROR DURING TRAINING\")\n    print(f\"{'='*70}\")\n    print(f\"Error: {str(e)}\")\n    print(f\"\\nPlease check:\")\n    print(f\"  1. GPU is enabled\")\n    print(f\"  2. Dataset paths are correct\")\n    print(f\"  3. Enough GPU memory (try reducing batch size)\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:56:36.840399Z","iopub.execute_input":"2025-12-09T19:56:36.840687Z"},"editable":false},"outputs":[{"name":"stdout","text":"======================================================================\nSTARTING BASELINE TRAINING\n======================================================================\nğŸ’¾ ResultsSaver initialized: /kaggle/working/baseline_yolov8n_640_20251209_195636\n\nğŸ“¥ Loading YOLOv8n pretrained model...\nâœ… Model loaded: yolov8n.pt\nğŸ“Š Model Information:\n   Total Parameters:     3,157,200\n   Trainable Parameters: 0\n   Model Size:           ~6.3 MB\n\n======================================================================\nğŸš€ STARTING TRAINING\n======================================================================\n\nâ±ï¸  Estimated Duration: 6-8 hours\nğŸ“Š Progress will be shown below\nâš ï¸  Do NOT close this notebook!\n\n======================================================================\n\nâ° Training started at: 2025-12-09 19:56:36\n\nUltralytics 8.3.235 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/train3, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=5\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 10.0Â±1.9 MB/s, size: 258.7 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/rdd-2022/RDD_SPLIT/train/labels... 26869 images, 8097 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 26869/26869 193.6it/s 2:19<0.0s\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/rdd-2022/RDD_SPLIT/train/images/Japan_006916.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/rdd-2022/RDD_SPLIT/train/images/Japan_011427.jpg: 1 duplicate labels removed\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/rdd-2022/RDD_SPLIT/train is not writable, cache not saved.\nWARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0m38.9GB RAM required to cache images with 50% safety margin but only 29.0/31.4GB available, not caching images\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 11.2Â±4.3 MB/s, size: 61.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/rdd-2022/RDD_SPLIT/val/labels... 5758 images, 1837 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5758/5758 210.3it/s 27.4s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/input/rdd-2022/RDD_SPLIT/val/images/Japan_006536.jpg: 1 duplicate labels removed\nWARNING âš ï¸ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/rdd-2022/RDD_SPLIT/val is not writable, cache not saved.\nWARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (5.9GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5758/5758 158.2it/s 36.4s<0.1s\nPlotting labels to /kaggle/working/runs/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/train3\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/100      2.21G      2.018      3.758      1.776         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1680/1680 4.5it/s 6:10<0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 180/180 5.4it/s 33.2s0.2ss\n                   all       5758       9740       0.32      0.262      0.203     0.0853\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      2/100      2.46G      1.968       2.89      1.703         46        640: 84% â”â”â”â”â”â”â”â”â”â”â”€â”€ 1410/1680 4.4it/s 4:54<1:01s","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nSAVE ALL RESULTS\nğŸš¨ RUN THIS CELL IMMEDIATELY AFTER TRAINING COMPLETES!\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"SAVING TRAINING RESULTS\")\nprint(\"=\"*70 + \"\\n\")\n\n# Verify results directory exists\nresults_dir = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name']\n\nif not results_dir.exists():\n    print(f\"âŒ Results directory not found: {results_dir}\")\n    print(f\"\\nSearching for results...\")\n    \n    runs_dir = Path(TRAINING_CONFIG['project'])\n    if runs_dir.exists():\n        for subdir in runs_dir.iterdir():\n            if subdir.is_dir():\n                print(f\"   Found: {subdir}\")\nelse:\n    print(f\"âœ… Results directory found: {results_dir}\\n\")\n    \n    # Save all training results\n    save_dir = saver.save_training_run(\n        model=model,\n        results_dir=results_dir,\n        config=TRAINING_CONFIG\n    )\n    \n    # Create downloadable archive\n    zip_path = saver.create_archive()\n    \n    print(\"âœ… Results saved successfully!\")\n    print(f\"\\nğŸ“¥ DOWNLOAD INSTRUCTIONS:\")\n    print(f\"   1. Look at the left sidebar â†’ Files\")\n    print(f\"   2. Navigate to /kaggle/working/\")\n    print(f\"   3. Find file: {Path(zip_path).name}\")\n    print(f\"   4. Right-click â†’ Download\")\n    print(f\"   5. Save to your computer NOW!\")\n    print(f\"\\nğŸš¨ DO THIS BEFORE CLOSING THE NOTEBOOK!\")\n    print(\"\\n\" + \"=\"*70 + \"\\n\")","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nVALIDATION ON TEST SET\nEvaluate the trained model on held-out test data\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"VALIDATION ON TEST SET\")\nprint(\"=\"*70 + \"\\n\")\n\n# Load best model\nbest_model_path = save_dir / \"weights\" / \"best.pt\"\n\nif not best_model_path.exists():\n    print(f\"âŒ Best model not found: {best_model_path}\")\nelse:\n    print(f\"âœ… Loading best model: {best_model_path}\\n\")\n    model_best = YOLO(str(best_model_path))\n    \n    # Validate on test set\n    print(\"ğŸ“Š Running validation on test set...\")\n    print(\"   This will take approximately 10-15 minutes\\n\")\n    \n    test_results = model_best.val(\n        data=str(data_yaml_path),\n        split='test',\n        imgsz=640,\n        batch=16,\n        device=0,\n        plots=True,\n        save_json=True,\n        save_hybrid=False,\n        conf=0.001,\n        iou=0.6,\n        max_det=300,\n        half=False,\n        dnn=False,\n        project='/kaggle/working/runs',\n        name='val_test',\n        verbose=True\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"TEST SET RESULTS\")\n    print(\"=\"*70)\n    print(f\"mAP@50:      {test_results.box.map50:.4f} ({test_results.box.map50*100:.2f}%)\")\n    print(f\"mAP@50-95:   {test_results.box.map:.4f} ({test_results.box.map*100:.2f}%)\")\n    print(f\"Precision:   {test_results.box.mp:.4f} ({test_results.box.mp*100:.2f}%)\")\n    print(f\"Recall:      {test_results.box.mr:.4f} ({test_results.box.mr*100:.2f}%)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # Save test results\n    test_results_dir = Path('/kaggle/working/runs/val_test')\n    if test_results_dir.exists():\n        test_save_dir = save_dir / \"test_results\"\n        test_save_dir.mkdir(exist_ok=True)\n        \n        for file in test_results_dir.glob('*'):\n            if file.is_file():\n                shutil.copy(file, test_save_dir / file.name)\n        \n        print(f\"âœ… Test results saved to: {test_save_dir}\")\n        \n        # Update archive with test results\n        print(\"\\nğŸ“¦ Updating archive with test results...\")\n        zip_path = saver.create_archive()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nANALYZE TRAINING RESULTS\nGenerate performance metrics and comparisons\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"RESULTS ANALYSIS\")\nprint(\"=\"*70 + \"\\n\")\n\n# Load training results\nresults_csv_path = save_dir / \"results.csv\"\n\nif not results_csv_path.exists():\n    print(f\"âŒ Results CSV not found: {results_csv_path}\")\nelse:\n    df_results = pd.read_csv(results_csv_path)\n    \n    # Get final epoch metrics\n    final_epoch = df_results.iloc[-1]\n    \n    # Determine column names (handle different Ultralytics versions)\n    map50_col = 'metrics/mAP50(B)' if 'metrics/mAP50(B)' in df_results.columns else 'metrics/mAP_0.5'\n    map_col = 'metrics/mAP50-95(B)' if 'metrics/mAP50-95(B)' in df_results.columns else 'metrics/mAP_0.5:0.95'\n    precision_col = 'metrics/precision(B)' if 'metrics/precision(B)' in df_results.columns else 'metrics/precision'\n    recall_col = 'metrics/recall(B)' if 'metrics/recall(B)' in df_results.columns else 'metrics/recall'\n    \n    # Create results table\n    results_table = pd.DataFrame({\n        'Experiment': [EXPERIMENT_NAME],\n        'Model': ['YOLOv8n'],\n        'Resolution': [640],\n        'Batch': [TRAINING_CONFIG['batch']],\n        'Epochs_Trained': [int(final_epoch['epoch']) + 1],\n        'mAP@50': [f\"{final_epoch[map50_col]:.4f}\"],\n        'mAP@50-95': [f\"{final_epoch[map_col]:.4f}\"],\n        'Precision': [f\"{final_epoch[precision_col]:.4f}\"],\n        'Recall': [f\"{final_epoch[recall_col]:.4f}\"],\n        'Parameters': ['3.2M'],\n        'AMP': [TRAINING_CONFIG['amp']],\n        'Status': ['âœ… Baseline']\n    })\n    \n    print(\"ğŸ“Š PERFORMANCE SUMMARY\")\n    print(\"=\"*70)\n    print(results_table.to_string(index=False))\n    print(\"=\"*70 + \"\\n\")\n    \n    # Save table\n    results_table.to_csv(save_dir / \"results_summary.csv\", index=False)\n    print(f\"âœ… Results table saved: {save_dir / 'results_summary.csv'}\")\n    \n    # Performance comparison with EDA targets\n    print(f\"\\nğŸ¯ TARGET vs ACHIEVED:\")\n    print(f\"=\"*70)\n    \n    target_map50 = 0.475  # Mid-point of 45-50% target\n    achieved_map50 = final_epoch[map50_col]\n    \n    print(f\"mAP@50:\")\n    print(f\"   Target:   45-50% ({target_map50:.4f})\")\n    print(f\"   Achieved: {achieved_map50*100:.2f}% ({achieved_map50:.4f})\")\n    \n    if achieved_map50 >= 0.45:\n        if achieved_map50 >= 0.50:\n            print(f\"   Status:   âœ… EXCEEDS TARGET!\")\n        else:\n            print(f\"   Status:   âœ… MEETS TARGET\")\n    else:\n        print(f\"   Status:   âš ï¸  Below target (but still valid baseline)\")\n    \n    print(f\"=\"*70 + \"\\n\")\n    \n    # Best epoch info\n    best_map50_idx = df_results[map50_col].idxmax()\n    best_epoch = df_results.iloc[best_map50_idx]\n    \n    print(f\"ğŸ“ˆ BEST EPOCH INFORMATION:\")\n    print(f\"=\"*70)\n    print(f\"Best Epoch:     {int(best_epoch['epoch']) + 1}\")\n    print(f\"Best mAP@50:    {best_epoch[map50_col]:.4f}\")\n    print(f\"Best mAP@50-95: {best_epoch[map_col]:.4f}\")\n    print(f\"Best Precision: {best_epoch[precision_col]:.4f}\")\n    print(f\"Best Recall:    {best_epoch[recall_col]:.4f}\")\n    print(f\"=\"*70 + \"\\n\")","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nVISUALIZE TRAINING CURVES\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\nprint(\"ğŸ“ˆ Generating training curves...\\n\")\n\n# Load results\ndf_results = pd.read_csv(save_dir / \"results.csv\")\n\n# Determine column names\nmap50_col = 'metrics/mAP50(B)' if 'metrics/mAP50(B)' in df_results.columns else 'metrics/mAP_0.5'\nmap_col = 'metrics/mAP50-95(B)' if 'metrics/mAP50-95(B)' in df_results.columns else 'metrics/mAP_0.5:0.95'\nprecision_col = 'metrics/precision(B)' if 'metrics/precision(B)' in df_results.columns else 'metrics/precision'\nrecall_col = 'metrics/recall(B)' if 'metrics/recall(B)' in df_results.columns else 'metrics/recall'\n\n# Create figure\nfig, axes = plt.subplots(2, 2, figsize=(18, 12))\nfig.suptitle(f'Training Curves - {EXPERIMENT_NAME}', fontsize=18, fontweight='bold')\n\n# 1. mAP curves\nax1 = axes[0, 0]\nax1.plot(df_results['epoch'], df_results[map50_col], label='mAP@50', linewidth=2, color='#2ecc71')\nax1.plot(df_results['epoch'], df_results[map_col], label='mAP@50-95', linewidth=2, color='#3498db')\nax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax1.set_ylabel('mAP', fontsize=12, fontweight='bold')\nax1.set_title('mAP Evolution', fontsize=14, fontweight='bold')\nax1.legend(fontsize=11)\nax1.grid(alpha=0.3)\n\n# Mark best epoch\nbest_epoch_idx = df_results[map50_col].idxmax()\nbest_map50 = df_results.iloc[best_epoch_idx][map50_col]\nbest_epoch_num = df_results.iloc[best_epoch_idx]['epoch']\nax1.scatter([best_epoch_num], [best_map50], color='red', s=100, zorder=5, label='Best')\nax1.legend(fontsize=11)\n\n# 2. Loss curves\nax2 = axes[0, 1]\nloss_cols = [col for col in df_results.columns if 'loss' in col.lower() and 'train' in col.lower()]\ncolors = ['#e74c3c', '#f39c12', '#9b59b6']\nfor i, col in enumerate(loss_cols[:3]):\n    label = col.replace('train/', '').replace('loss', '').strip()\n    ax2.plot(df_results['epoch'], df_results[col], label=label, linewidth=2, color=colors[i % len(colors)])\nax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax2.set_ylabel('Loss', fontsize=12, fontweight='bold')\nax2.set_title('Training Losses', fontsize=14, fontweight='bold')\nax2.legend(fontsize=11)\nax2.grid(alpha=0.3)\n\n# 3. Precision & Recall\nax3 = axes[1, 0]\nax3.plot(df_results['epoch'], df_results[precision_col], label='Precision', linewidth=2, color='#3498db')\nax3.plot(df_results['epoch'], df_results[recall_col], label='Recall', linewidth=2, color='#e74c3c')\nax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax3.set_ylabel('Metric', fontsize=12, fontweight='bold')\nax3.set_title('Precision & Recall', fontsize=14, fontweight='bold')\nax3.legend(fontsize=11)\nax3.grid(alpha=0.3)\n\n# 4. Learning rate\nax4 = axes[1, 1]\nlr_cols = [col for col in df_results.columns if 'lr' in col.lower()]\nfor col in lr_cols:\n    ax4.plot(df_results['epoch'], df_results[col], label=col.replace('lr/', 'LR: '), linewidth=2)\nax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\nax4.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\nif lr_cols:\n    ax4.legend(fontsize=11)\nax4.grid(alpha=0.3)\nax4.set_yscale('log')\n\nplt.tight_layout()\nplt.savefig(save_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"âœ… Training curves saved: {save_dir / 'training_curves.png'}\\n\")\n\n# Update archive\nprint(\"ğŸ“¦ Updating archive with training curves...\")\nzip_path = saver.create_archive()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nFINAL SUMMARY & NEXT STEPS\n\"\"\"\n\nprint(\"â•”\" + \"=\"*68 + \"â•—\")\nprint(\"â•‘\" + \" \"*18 + \"BASELINE TRAINING COMPLETE!\" + \" \"*23 + \"â•‘\")\nprint(\"â•š\" + \"=\"*68 + \"â•\")\n\nprint(f\"\\nğŸ“Š Experiment: {EXPERIMENT_NAME}\")\nprint(f\"â° Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n\nif 'final_metrics' in saver.metadata:\n    metrics = saver.metadata['final_metrics']\n    print(f\"\\nğŸ¯ FINAL PERFORMANCE:\")\n    print(f\"=\"*70)\n    print(f\"   mAP@50:      {metrics['mAP50']:.4f} ({metrics['mAP50']*100:.2f}%)\")\n    print(f\"   mAP@50-95:   {metrics['mAP50-95']:.4f} ({metrics['mAP50-95']*100:.2f}%)\")\n    print(f\"   Precision:   {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\")\n    print(f\"   Recall:      {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\")\n    print(f\"=\"*70)\n    \n    # Performance evaluation\n    if metrics['mAP50'] >= 0.45:\n        print(f\"\\nâœ… SUCCESS: Baseline meets/exceeds target (45-50% mAP@50)\")\n    else:\n        print(f\"\\nâš ï¸  Note: Below target but still valid baseline\")\n\nprint(f\"\\nğŸ“ ALL RESULTS SAVED TO:\")\nprint(f\"   Directory: {save_dir}\")\nprint(f\"   Archive:   {zip_path}\")\nprint(f\"   Size:      {Path(zip_path).stat().st_size / (1024*1024):.2f} MB\")\n\nprint(f\"\\nğŸš¨ CRITICAL: DOWNLOAD RESULTS NOW!\")\nprint(f\"=\"*70)\nprint(f\"1. Go to left sidebar â†’ Files\")\nprint(f\"2. Navigate to /kaggle/working/\")\nprint(f\"3. Find: {Path(zip_path).name}\")\nprint(f\"4. Right-click â†’ Download\")\nprint(f\"5. Save to your computer\")\nprint(f\"=\"*70)\n\nprint(f\"\\nâœ… What You've Accomplished:\")\nprint(f\"   âœ… Trained YOLOv8n baseline model\")\nprint(f\"   âœ… Achieved {metrics['mAP50']*100:.2f}% mAP@50\")\nprint(f\"   âœ… Generated 15+ training plots\")\nprint(f\"   âœ… Saved all weights and metrics\")\nprint(f\"   âœ… Established performance benchmark\")\nprint(f\"   âœ… Used AMP for optimal speed\")\n\nprint(f\"\\nğŸš€ NEXT STEPS (Week 4):\")\nprint(f\"=\"*70)\nprint(f\"1. ğŸ“¥ Download and backup all results\")\nprint(f\"2. ğŸ“Š Document baseline in project log\")\nprint(f\"3. ğŸ”¬ Create new notebook: 'RDD2022 - YOLOv8s @ 640'\")\nprint(f\"4. ğŸ¯ Target: 52-57% mAP@50 (7-12% improvement)\")\nprint(f\"5. â±ï¸  GPU Time: ~15 hours\")\n\nprint(f\"\\nğŸ“‹ 8-WEEK PROGRESS:\")\nprint(f\"=\"*70)\nprint(f\"   âœ… Week 1:   EDA Complete\")\nprint(f\"   âœ… Week 2-3: Baseline (YOLOv8n @ 640) - {metrics['mAP50']*100:.2f}% mAP@50\")\nprint(f\"   â­ï¸  Week 4:   Model Scaling (YOLOv8s @ 640)\")\nprint(f\"   â­ï¸  Week 5-6: Resolution (YOLOv8s @ 1024)\")\nprint(f\"   â­ï¸  Week 7:   Optimization (TTA + Tuning)\")\nprint(f\"   â­ï¸  Week 8:   Documentation & Patent\")\n\nprint(f\"\\nğŸ’¡ Key Features Used:\")\nprint(f\"   â€¢ NumPy 1.26.4 (stable compatibility)\")\nprint(f\"   â€¢ AMP enabled (15% faster training)\")\nprint(f\"   â€¢ Auto-generated plots (15+ visualizations)\")\nprint(f\"   â€¢ Complete results archiving\")\nprint(f\"   â€¢ GPU: {torch.cuda.get_device_name(0)}\")\n\nprint(f\"\\nğŸ“ Recommended Next Model:\")\nprint(f\"=\"*70)\nprint(f\"   Model:      yolov8s.pt  (11.2M params vs 3.2M)\")\nprint(f\"   Resolution: 640Ã—640     (same as baseline)\")\nprint(f\"   Epochs:     100         (same as baseline)\")\nprint(f\"   Batch:      16          (same as baseline)\")\nprint(f\"   Expected:   +7-12% mAP improvement\")\nprint(f\"=\"*70)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ‰ CONGRATULATIONS! Professional baseline complete!\")\nprint(\"=\"*70 + \"\\n\")\n\n# Save this summary\nsummary_path = save_dir / \"FINAL_SUMMARY.txt\"\nwith open(summary_path, 'w') as f:\n    f.write(f\"\"\"\nBASELINE TRAINING SUMMARY\n{'='*70}\n\nExperiment:     {EXPERIMENT_NAME}\nCompleted:      {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\nPERFORMANCE:\n   mAP@50:      {metrics['mAP50']:.4f} ({metrics['mAP50']*100:.2f}%)\n   mAP@50-95:   {metrics['mAP50-95']:.4f} ({metrics['mAP50-95']*100:.2f}%)\n   Precision:   {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\n   Recall:      {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\n\nCONFIGURATION:\n   Model:       YOLOv8n\n   Resolution:  640Ã—640\n   Epochs:      {TRAINING_CONFIG['epochs']}\n   Batch:       {TRAINING_CONFIG['batch']}\n   Parameters:  3.2M\n   AMP:         {TRAINING_CONFIG['amp']}\n   Plots:       {TRAINING_CONFIG['plots']}\n\nSTATUS: âœ… BASELINE ESTABLISHED\n\nNEXT: Scale to YOLOv8s for improved performance\n\"\"\")\n\nprint(f\"âœ… Final summary saved: {summary_path}\")\n\n# Final archive update\nprint(f\"\\nğŸ“¦ Creating final archive...\")\nzip_path = saver.create_archive()\n\nprint(f\"\\n{'='*70}\")\nprint(f\"âœ… ALL DONE! Download {Path(zip_path).name} NOW!\")\nprint(f\"{'='*70}\\n\")","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}