{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "#VSC-559b2faf",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "# RDD2022 India Dataset - Verification\n",
    "\n",
    "**Week 1: Dataset Preparation and Verification**\n",
    "\n",
    "**Objectives:**\n",
    "1. Verify dataset structure\n",
    "2. Count and validate files\n",
    "3. Check XML annotation format\n",
    "4. Generate dataset statistics\n",
    "5. Prepare for Week 2 EDA\n",
    "\n",
    "**Dataset Information:**\n",
    "- Source: RDD2022 Competition\n",
    "- Region: India\n",
    "- Format: Pascal VOC XML annotations\n",
    "- Classes: 6 grouped categories\n",
    "  - Longitudinal (D00, D01)\n",
    "  - Transverse (D10, D11)\n",
    "  - Alligator (D20)\n",
    "  - Pothole (D40)\n",
    "  - Marking Blur (D43, D44)\n",
    "  - Other (D50)\n",
    "\n",
    "**Note:** Test annotations are not provided (standard for competitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-ce91e33e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTS AND SETUP\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "# Image validation\n",
    "try:\n",
    "    from PIL import Image\n",
    "    PIL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PIL_AVAILABLE = False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  WEEK 1: DATASET VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-a1fbd784",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Validation options\n",
    "VALIDATE_IMAGES = True\n",
    "VALIDATE_XMLS = True\n",
    "VALIDATION_SAMPLE = 100\n",
    "GENERATE_STATS = True\n",
    "\n",
    "# Class mapping: Original RDD2022 classes → Grouped classes\n",
    "CLASS_MAPPING = {\n",
    "    'D00': 'longitudinal',\n",
    "    'D01': 'longitudinal',\n",
    "    'D10': 'transverse',\n",
    "    'D11': 'transverse',\n",
    "    'D20': 'alligator',\n",
    "    'D40': 'pothole',\n",
    "    'D43': 'marking_blur',\n",
    "    'D44': 'marking_blur',\n",
    "    'D50': 'other',\n",
    "    'D0w0': 'longitudinal'\n",
    "}\n",
    "\n",
    "GROUPED_CLASSES = ['longitudinal', 'transverse', 'alligator',\n",
    "                   'pothole', 'marking_blur', 'other']\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Image validation: {VALIDATE_IMAGES}\")\n",
    "print(f\"  XML validation: {VALIDATE_XMLS}\")\n",
    "print(f\"  Validation sample: {VALIDATION_SAMPLE}\")\n",
    "print(f\"  Generate statistics: {GENERATE_STATS}\")\n",
    "print(f\"  Grouped classes: {len(GROUPED_CLASSES)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-291b15ac",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MOUNT DRIVE AND LOAD CONFIG\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[STEP 1/6] SETUP\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/ML/road-damage-detection\")\n",
    "config_file = PROJECT_ROOT / \"config.json\"\n",
    "\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"[OK] Configuration loaded\")\n",
    "else:\n",
    "    print(\"[WARNING] No config.json found\")\n",
    "    config = {}\n",
    "\n",
    "DATASET_DIR = Path(config.get('dataset_raw', str(PROJECT_ROOT / 'datasets/rdd2022/India')))\n",
    "RESULTS_DIR = Path(config.get('results_dir', str(PROJECT_ROOT / 'results')))\n",
    "\n",
    "os.chdir(PROJECT_ROOT / 'notebooks')\n",
    "\n",
    "print(f\"[OK] Project root: {PROJECT_ROOT.name}\")\n",
    "print(f\"[OK] Dataset: {DATASET_DIR}\")\n",
    "print(f\"[OK] Working directory: {os.getcwd()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-8a44f383",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VERIFY DIRECTORY STRUCTURE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[STEP 2/6] VERIFYING STRUCTURE\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "required_paths = {\n",
    "    'train_images': DATASET_DIR / 'train/images',\n",
    "    'train_annotations': DATASET_DIR / 'train/annotations/xmls',\n",
    "    'test_images': DATASET_DIR / 'test/images',\n",
    "}\n",
    "\n",
    "all_exist = True\n",
    "for name, path in required_paths.items():\n",
    "    exists = path.exists()\n",
    "    is_dir = path.is_dir() if exists else False\n",
    "\n",
    "    if exists and is_dir:\n",
    "        print(f\"  [OK] {name}\")\n",
    "    else:\n",
    "        print(f\"  [ERROR] {name} - NOT FOUND\")\n",
    "        all_exist = False\n",
    "\n",
    "test_annotations = DATASET_DIR / 'test/annotations/xmls'\n",
    "if not test_annotations.exists():\n",
    "    print(f\"  [INFO] test_annotations - Not provided (expected)\")\n",
    "\n",
    "if not all_exist:\n",
    "    raise FileNotFoundError(\"Dataset structure incomplete\")\n",
    "\n",
    "print(\"\\n[OK] Directory structure verified\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-892be7d7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COUNT FILES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[STEP 3/6] COUNTING FILES\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "train_imgs = list((DATASET_DIR / 'train/images').glob('*.jpg'))\n",
    "train_xmls = list((DATASET_DIR / 'train/annotations/xmls').glob('*.xml'))\n",
    "test_imgs = list((DATASET_DIR / 'test/images').glob('*.jpg'))\n",
    "\n",
    "file_counts = {\n",
    "    'train': {'images': len(train_imgs), 'annotations': len(train_xmls)},\n",
    "    'test': {'images': len(test_imgs), 'annotations': 0}\n",
    "}\n",
    "\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(f\"  Images:      {len(train_imgs):>6,}\")\n",
    "print(f\"  Annotations: {len(train_xmls):>6,}\")\n",
    "\n",
    "if len(train_imgs) != len(train_xmls):\n",
    "    diff = abs(len(train_imgs) - len(train_xmls))\n",
    "    print(f\"  [WARNING] Mismatch: {diff} files\")\n",
    "\n",
    "print(f\"\\nTEST:\")\n",
    "print(f\"  Images:      {len(test_imgs):>6,}\")\n",
    "print(f\"  Annotations: Not provided\")\n",
    "\n",
    "total_images = len(train_imgs) + len(test_imgs)\n",
    "total_annotations = len(train_xmls)\n",
    "\n",
    "print(f\"\\nTOTAL:\")\n",
    "print(f\"  Images:      {total_images:>6,}\")\n",
    "print(f\"  Annotations: {total_annotations:>6,}\")\n",
    "\n",
    "if total_images == 0:\n",
    "    raise ValueError(\"Dataset appears empty\")\n",
    "\n",
    "print(\"\\n[OK] File counting complete\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-803a8f7c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VALIDATE SAMPLE FILES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[STEP 4/6] VALIDATING SAMPLES\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "validation_results = {\n",
    "    'images_checked': 0,\n",
    "    'images_valid': 0,\n",
    "    'images_invalid': 0,\n",
    "    'xmls_checked': 0,\n",
    "    'xmls_valid': 0,\n",
    "    'xmls_invalid': 0,\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "if VALIDATION_SAMPLE and VALIDATION_SAMPLE < len(train_imgs):\n",
    "    sample_images = train_imgs[:VALIDATION_SAMPLE]\n",
    "    print(f\"Validating {VALIDATION_SAMPLE} sample files...\")\n",
    "else:\n",
    "    sample_images = train_imgs\n",
    "    print(f\"Validating all {len(train_imgs):,} files...\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for img_path in tqdm(sample_images, desc=\"  Progress\"):\n",
    "    # Validate image\n",
    "    if VALIDATE_IMAGES and PIL_AVAILABLE:\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "            validation_results['images_valid'] += 1\n",
    "        except Exception as e:\n",
    "            validation_results['images_invalid'] += 1\n",
    "            validation_results['errors'].append(f\"Image error: {img_path.name}\")\n",
    "\n",
    "        validation_results['images_checked'] += 1\n",
    "\n",
    "    # Validate corresponding XML\n",
    "    xml_path = DATASET_DIR / 'train/annotations/xmls' / f\"{img_path.stem}.xml\"\n",
    "\n",
    "    if VALIDATE_XMLS and xml_path.exists():\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            filename = root.find('filename')\n",
    "            if filename is None:\n",
    "                raise ValueError(\"Missing filename tag\")\n",
    "            validation_results['xmls_valid'] += 1\n",
    "        except Exception as e:\n",
    "            validation_results['xmls_invalid'] += 1\n",
    "            error_msg = str(e)[:50]\n",
    "            validation_results['errors'].append(f\"XML error: {xml_path.name} - {error_msg}\")\n",
    "\n",
    "        validation_results['xmls_checked'] += 1\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Images checked: {validation_results['images_checked']:,}\")\n",
    "print(f\"  Images valid: {validation_results['images_valid']:,}\")\n",
    "print(f\"  Images invalid: {validation_results['images_invalid']:,}\")\n",
    "print(f\"  XMLs checked: {validation_results['xmls_checked']:,}\")\n",
    "print(f\"  XMLs valid: {validation_results['xmls_valid']:,}\")\n",
    "print(f\"  XMLs invalid: {validation_results['xmls_invalid']:,}\")\n",
    "\n",
    "if validation_results['errors']:\n",
    "    print(f\"\\n[WARNING] Found {len(validation_results['errors'])} errors\")\n",
    "    for error in validation_results['errors'][:5]:\n",
    "        print(f\"  {error}\")\n",
    "    if len(validation_results['errors']) > 5:\n",
    "        print(f\"  ... and {len(validation_results['errors']) - 5} more\")\n",
    "\n",
    "if validation_results['images_invalid'] == 0 and validation_results['xmls_invalid'] == 0:\n",
    "    print(\"\\n[OK] All validated files are valid\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-41a48d6b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GENERATE STATISTICS WITH CLASS GROUPING\n",
    "# ============================================\n",
    "\n",
    "if GENERATE_STATS:\n",
    "    print(\"\\n[STEP 5/6] GENERATING STATISTICS\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    stats = {\n",
    "        'dataset': 'RDD2022 India',\n",
    "        'verification_date': datetime.now().isoformat(),\n",
    "        'file_counts': file_counts,\n",
    "        'total_images': total_images,\n",
    "        'total_annotations': total_annotations,\n",
    "        'validation_results': validation_results,\n",
    "        'class_mapping': CLASS_MAPPING,\n",
    "        'grouped_classes': GROUPED_CLASSES,\n",
    "        'original_class_distribution': {},\n",
    "        'grouped_class_distribution': {},\n",
    "        'total_objects': 0,\n",
    "        'negative_samples': 0,\n",
    "        'unknown_classes': []\n",
    "    }\n",
    "\n",
    "    print(\"Analyzing annotations...\")\n",
    "\n",
    "    original_counts = Counter()\n",
    "    grouped_counts = Counter()\n",
    "    total_objects = 0\n",
    "    negative_count = 0\n",
    "    unknown_classes = set()\n",
    "\n",
    "    for xml_path in tqdm(train_xmls, desc=\"  Progress\"):\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            objects = root.findall('object')\n",
    "\n",
    "            if len(objects) == 0:\n",
    "                negative_count += 1\n",
    "            else:\n",
    "                for obj in objects:\n",
    "                    damage_type = obj.find('name').text\n",
    "                    original_counts[damage_type] += 1\n",
    "                    total_objects += 1\n",
    "\n",
    "                    # Map to grouped class\n",
    "                    if damage_type in CLASS_MAPPING:\n",
    "                        grouped_class = CLASS_MAPPING[damage_type]\n",
    "                        grouped_counts[grouped_class] += 1\n",
    "                    else:\n",
    "                        unknown_classes.add(damage_type)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    stats['original_class_distribution'] = dict(original_counts)\n",
    "    stats['grouped_class_distribution'] = dict(grouped_counts)\n",
    "    stats['total_objects'] = total_objects\n",
    "    stats['negative_samples'] = negative_count\n",
    "    stats['unknown_classes'] = list(unknown_classes)\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"  Total images: {total_images:,}\")\n",
    "    print(f\"  Total objects: {total_objects:,}\")\n",
    "    print(f\"  Negative samples: {negative_count:,}\")\n",
    "\n",
    "    print(\"\\nOriginal Class Distribution:\")\n",
    "    for cls in sorted(original_counts.keys()):\n",
    "        count = original_counts[cls]\n",
    "        pct = (count / total_objects * 100) if total_objects > 0 else 0\n",
    "        print(f\"  {cls}: {count:>6,} ({pct:5.1f}%)\")\n",
    "\n",
    "    print(\"\\nGrouped Class Distribution:\")\n",
    "    for cls in GROUPED_CLASSES:\n",
    "        count = grouped_counts.get(cls, 0)\n",
    "        pct = (count / total_objects * 100) if total_objects > 0 else 0\n",
    "        print(f\"  {cls:15s}: {count:>6,} ({pct:5.1f}%)\")\n",
    "\n",
    "    if unknown_classes:\n",
    "        print(f\"\\n[WARNING] Unknown classes found: {list(unknown_classes)}\")\n",
    "\n",
    "    # Save statistics\n",
    "    stats_file = RESULTS_DIR / 'dataset_verification.json'\n",
    "    RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "\n",
    "    print(f\"\\n[OK] Statistics saved: {stats_file.name}\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\n[STEP 5/6] STATISTICS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"[SKIP] Statistics generation disabled\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-48edc1e5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SAMPLE XML INSPECTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[STEP 6/6] SAMPLE INSPECTION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "sample_xml = train_xmls[0]\n",
    "tree = ET.parse(sample_xml)\n",
    "root = tree.getroot()\n",
    "\n",
    "filename = root.find('filename').text\n",
    "size = root.find('size')\n",
    "width = int(size.find('width').text)\n",
    "height = int(size.find('height').text)\n",
    "objects = root.findall('object')\n",
    "\n",
    "print(f\"\\nSample file: {sample_xml.name}\")\n",
    "print(f\"  Filename: {filename}\")\n",
    "print(f\"  Size: {width}x{height}\")\n",
    "print(f\"  Objects: {len(objects)}\")\n",
    "\n",
    "if len(objects) > 0:\n",
    "    print(\"\\n  Sample annotations:\")\n",
    "    for i, obj in enumerate(objects[:3], 1):\n",
    "        name = obj.find('name').text\n",
    "        grouped = CLASS_MAPPING.get(name, 'unknown')\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)\n",
    "        ymin = int(bbox.find('ymin').text)\n",
    "        xmax = int(bbox.find('xmax').text)\n",
    "        ymax = int(bbox.find('ymax').text)\n",
    "\n",
    "        print(f\"    {i}. Original: {name} → Grouped: {grouped}\")\n",
    "        print(f\"       BBox: ({xmin}, {ymin}) to ({xmax}, {ymax})\")\n",
    "        print(f\"       Size: {xmax-xmin}x{ymax-ymin}\")\n",
    "\n",
    "print(\"\\n[OK] Sample inspection complete\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "#VSC-a4533462",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET PREPARATION - COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"   Location: {DATASET_DIR}\")\n",
    "print(f\"   Total Images: {stats['total_images']}\")\n",
    "print(f\"   Total Objects: {stats['total_objects']}\")\n",
    "print(f\"   Negative Samples: {stats['negative_samples']}\")\n",
    "\n",
    "print(\"\\nOriginal Classes (8 types):\")\n",
    "for cls in sorted(CLASS_MAPPING.keys()):\n",
    "    print(f\"   • {cls}\")\n",
    "\n",
    "print(\"\\nGrouped Classes (6 types):\")\n",
    "for cls in GROUPED_CLASSES:\n",
    "    print(f\"   • {cls}\")\n",
    "\n",
    "print(\"\\nVerification Status:\")\n",
    "print(\"   ✓ Directory structure verified\")\n",
    "print(\"   ✓ File counts confirmed\")\n",
    "print(\"   ✓ Annotation validation complete\")\n",
    "print(\"   ✓ Statistics generated and saved\")\n",
    "print(\"   ✓ Sample inspection verified\")\n",
    "\n",
    "print(\"\\nOutput Files:\")\n",
    "print(f\"   • {RESULTS_DIR / 'dataset_verification.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS - Week 2: Exploratory Data Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(\"\")\n",
    "print(\"Coming up in 02_explore_data.ipynb:\")\n",
    "print(\"   1. Visualize class distributions\")\n",
    "print(\"   2. Analyze image properties (size, aspect ratio)\")\n",
    "print(\"   3. Examine bounding box statistics\")\n",
    "print(\"   4. Check for class imbalances\")\n",
    "print(\"   5. Generate sample visualizations\")\n",
    "print(\"   6. Create comprehensive EDA report\")\n",
    "print(\"\")\n",
    "print(\"The dataset is ready for analysis!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}