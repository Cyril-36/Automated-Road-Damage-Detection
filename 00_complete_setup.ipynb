{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GybwM3ALE9vA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GybwM3ALE9vA"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COMPLETE PROJECT SETUP\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  ROAD DAMAGE DETECTION - COMPLETE SETUP\")\n",
    "print(\"  Location: Google Drive/ML folder\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ============================================\n",
    "# [1/7] MOUNT GOOGLE DRIVE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[1/7] MOUNTING GOOGLE DRIVE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"   [OK] Google Drive mounted\")\n",
    "\n",
    "# ============================================\n",
    "# [2/7] CREATE PROJECT STRUCTURE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[2/7] CREATING PROJECT STRUCTURE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/ML/road-damage-detection\")\n",
    "\n",
    "# Complete directory structure\n",
    "folders = [\n",
    "    'notebooks',\n",
    "    'datasets/rdd2022/India/train/images',\n",
    "    'datasets/rdd2022/India/train/annotations/xmls',\n",
    "    'datasets/rdd2022/India/test/images',\n",
    "    'datasets/rdd2022/India/test/annotations/xmls',\n",
    "    'datasets/rdd2022_yolo_india/images/train',\n",
    "    'datasets/rdd2022_yolo_india/images/val',\n",
    "    'datasets/rdd2022_yolo_india/images/test',\n",
    "    'datasets/rdd2022_yolo_india/labels/train',\n",
    "    'datasets/rdd2022_yolo_india/labels/val',\n",
    "    'datasets/rdd2022_yolo_india/labels/test',\n",
    "    'results/exploration',\n",
    "    'results/evaluation',\n",
    "    'runs/detect',\n",
    "    'weights',\n",
    "    'logs'\n",
    "]\n",
    "\n",
    "# Create directories\n",
    "created_count = 0\n",
    "existing_count = 0\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = PROJECT_ROOT / folder\n",
    "    if not folder_path.exists():\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        created_count += 1\n",
    "    else:\n",
    "        existing_count += 1\n",
    "\n",
    "print(f\"   Created: {created_count} new folders\")\n",
    "print(f\"   Existing: {existing_count} folders\")\n",
    "print(\"   [OK] Project structure ready\")\n",
    "\n",
    "# ============================================\n",
    "# [3/7] INSTALL PACKAGES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[3/7] INSTALLING PACKAGES\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "packages = [\n",
    "    'ultralytics',\n",
    "    'opencv-python-headless',\n",
    "    'pillow',\n",
    "    'tqdm',\n",
    "    'scikit-learn',\n",
    "    'seaborn'\n",
    "]\n",
    "\n",
    "print(f\"Installing {len(packages)} packages...\")\n",
    "for package in packages:\n",
    "    os.system(f'pip install -q {package}')\n",
    "\n",
    "print(\"   [OK] All packages installed\")\n",
    "\n",
    "# ============================================\n",
    "# [4/7] VERIFY INSTALLATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[4/7] VERIFYING INSTALLATIONS\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   OpenCV: {cv2.__version__}\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"   GPU: Not available (CPU mode)\")\n",
    "\n",
    "print(\"   [OK] All packages verified\")\n",
    "\n",
    "# ============================================\n",
    "# [5/7] CREATE CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[5/7] CREATING PROJECT CONFIGURATION\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "config = {\n",
    "    'project_name': 'road-damage-detection',\n",
    "    'project_root': str(PROJECT_ROOT),\n",
    "    'dataset_raw': str(PROJECT_ROOT / 'datasets/rdd2022/India'),\n",
    "    'dataset_yolo': str(PROJECT_ROOT / 'datasets/rdd2022_yolo_india'),\n",
    "    'results_dir': str(PROJECT_ROOT / 'results'),\n",
    "    'runs_dir': str(PROJECT_ROOT / 'runs'),\n",
    "    'weights_dir': str(PROJECT_ROOT / 'weights'),\n",
    "    'logs_dir': str(PROJECT_ROOT / 'logs'),\n",
    "    'device': 'cuda',\n",
    "    'random_seed': 42,\n",
    "    \n",
    "    'class_names': ['longitudinal', 'transverse', 'alligator', 'pothole', 'marking_blur', 'other'],\n",
    "    \n",
    "    'class_mapping': {\n",
    "        'D00': 'longitudinal',\n",
    "        'D01': 'longitudinal',\n",
    "        'D10': 'transverse',\n",
    "        'D11': 'transverse',\n",
    "        'D20': 'alligator',\n",
    "        'D40': 'pothole',\n",
    "        'D43': 'marking_blur',\n",
    "        'D44': 'marking_blur',\n",
    "        'D50': 'other',\n",
    "        'D0w0': 'longitudinal'\n",
    "    },\n",
    "    \n",
    "    'num_classes': 6,\n",
    "    'img_size': 640,\n",
    "    'batch_size': 16,\n",
    "    'train_ratio': 0.7,\n",
    "    'val_ratio': 0.2,\n",
    "    'test_ratio': 0.1,\n",
    "    'model': 'yolov8n.pt',\n",
    "    'epochs': 100,\n",
    "    'patience': 20\n",
    "}\n",
    "\n",
    "config_file = PROJECT_ROOT / 'config.json'\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"   [OK] Configuration saved: config.json\")\n",
    "print(f\"       Classes: {config['num_classes']}\")\n",
    "print(f\"       Location: {config_file}\")\n",
    "\n",
    "# ============================================\n",
    "# [6/7] CREATE YOLO DATA CONFIG\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[6/7] CREATING YOLO DATA CONFIG\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "yolo_config = f\"\"\"path: {config['dataset_yolo']}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "nc: {config['num_classes']}\n",
    "names: {config['class_names']}\n",
    "\"\"\"\n",
    "\n",
    "data_yaml = PROJECT_ROOT / 'datasets/rdd2022_yolo_india/data.yaml'\n",
    "with open(data_yaml, 'w') as f:\n",
    "    f.write(yolo_config)\n",
    "\n",
    "print(f\"   [OK] YOLO config saved: data.yaml\")\n",
    "print(f\"       Classes: {config['num_classes']}\")\n",
    "\n",
    "# ============================================\n",
    "# [7/7] SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n[7/7] SETUP COMPLETE\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  SETUP COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nProject Structure:\")\n",
    "print(f\"  Root: {PROJECT_ROOT.name}/\")\n",
    "print(f\"  Folders: {created_count + existing_count}\")\n",
    "print(f\"  Config: config.json ✓\")\n",
    "print(f\"  YOLO config: data.yaml ✓\")\n",
    "\n",
    "print(\"\\nClass Structure:\")\n",
    "print(f\"  Grouped classes: {config['num_classes']}\")\n",
    "for i, cls in enumerate(config['class_names'], 1):\n",
    "    print(f\"    {i}. {cls}\")\n",
    "\n",
    "print(\"\\nPackages:\")\n",
    "print(\"  ✓ PyTorch + CUDA\")\n",
    "print(\"  ✓ Ultralytics YOLOv8\")\n",
    "print(\"  ✓ OpenCV, PIL, pandas\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Download RDD2022 dataset\")\n",
    "print(\"  2. Extract to datasets/rdd2022/India/\")\n",
    "print(\"  3. Run 01_prepare_dataset.ipynb\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}